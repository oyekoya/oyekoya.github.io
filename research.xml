<?xml version="1.0" encoding="8859-1"?>
<links>
	<menu title="Intro" intro="Welcome to my website">
		<mydata type="description"><![CDATA[<p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>About Current Research:</b> I currently work in the <a href="http://vecg.cs.ucl.ac.uk/" target = "_blank"><u>Virtual Environments and Computer Graphics Group</u></a> at the University <sbr />College London since January 2008.</font></p><p align="left"><font face="Arial" size="11" color="#000099">- EU Project &quot;<a href="http://www.beaming-eu.org/" target = "_blank"><u>Beaming</u></a>&quot;</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- EU Project &quot;<a href="http://www.presenccia.org/" target = "_blank"><u>Presenccia: Presence Research</u></a>&quot;</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- EPSRC project &quot;<a href="http://gow.epsrc.ac.uk/ViewGrant.aspx?GrantRef=EP/E010032/1" target = "_blank"><u>Eye Catching: Supporting Tele-communicational Eye-gaze in Collaborative Virtual Environments</u></a>&quot;</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Reporting to: <a href="http://www.cs.ucl.ac.uk/staff/A.Steed/" target = "_blank"><u>Dr Anthony Steed</u></a></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>About Previous Research:</b></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Research focus: 3D Visualization of Retrieved PET Images.</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Project: EU-funded TIME (Tele-Imaging in Medicine)</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Reported to: <a href="http://www.cs.mdx.ac.uk/staffpages/xiaohong/" target = "_blank"><u>Dr Xiaohong Gao</u></a></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>PhD Research:</b></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Eye Tracking: A Perceptual Interface for Content Based Image Retrieval - Download <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/thesis/Thesis.pdf" target = "_blank"><u>Thesis</u></a></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">- Academic Supervisor: <a href="http://www.ee.ucl.ac.uk/%7Efstentif/" target = "_blank"><u>Fred Stentiford</u></a> </font></p><br/><p align="center"><font face="Arial" size="11" color="#FF0000"><a href="http://www.youtube.com/user/woleucl/videos" target="_blank">Visit my youtube channel to view some demos of my work</a></font></p>]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">1.flv</mydata>
	</menu>
	<menu title="Profile" intro="PROFILE">
		<mydata type="description"><![CDATA[<p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>CV</b></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">Researcher and specialist in the field of imaging, 3D and human computer interaction, with hands-on <sbr />project work experience in R&amp;D within industry and academia. I have published and presented several <sbr />refereed papers/articles covering advances in multimedia technology in book chapters, journals and <sbr />international conferences. My interest lies in models of behavioural simulation on virtual characters in immersive virtual environments. I also have an interest in learning in virtual environments.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>Key Skills</b></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">C, C++, Matlab, VB.Net, ASP.Net, SQL Server</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><b>Professional Experience</b></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><a href="http://www.ucl.ac.uk" target = "_blank">University College London</a></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><a href="http://www.mdx.ac.uk/" target = "_blank">Middlesex University</a></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><a href="http://www.btplc.com/" target = "_blank">British Telecommunications Plc</a></font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><a href="http://www.nortel.com/" target = "_blank">Nortel Networks Plc</a></font></p>]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">1.flv</mydata>
	</menu>
	<menu title="Research1" intro="Attention Model">
		<mydata type="description"><![CDATA[<p></p><p align="justify"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">This research models automatic attention behaviour using a saliency model that generates plausible targets for combined gaze and head motions. The attention model was integrated into an OpenSG application and the open-source Second Life client. Studies in both systems demonstrated a promising attention model that is not just believable and realistic but also adaptable to varying task, without any prior knowledge of the virtual scene.</font></p>]]></mydata>
		<mydata type="image">attentionmodel.jpg</mydata>
		<mydata type="video">attentionmodel.flv</mydata>
		<mydata type="video">head_eye_model.flv</mydata>
	</menu>
	<menu title="Research2" intro="EU FP7 Beaming Project">
		<mydata type="description"><![CDATA[<p></p><p align="justify"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">The EU Beaming project aims to give people a real sense of physically being in a remote location with other people, and vice versa, without actually physically travelling. When we interact with others we pay the most attention to the face because it conveys eye gaze, head movement, expressions and gestures and are used as a crucial channel of communication. Therefore, we propose the use of spherical displays to represent telepresent visitors' head at a remote location.</font></p>]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">chi_sphere_avatar.flv</mydata>
	</menu>
	<menu title="Research3" intro="EPSRC Eye Catching Project">
		<mydata type="description"><![CDATA[<p align="left"></p><p align="justify"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">The project aimed to support eye-gaze as a key interactional resource in collaboration. The virtual characters are controlled by human subjects in a cave-like facility (<a href="http://www.cs.ucl.ac.uk/research/vr/Projects/Cave/" target = "_blank"><u>immersive virtual environment</u></a>). &nbsp;Low-latency precision head-tracking allows distortion-free and lag-free movement through the virtual environment. Interaction with and navigation through the environment are achieved via a hand-held tracking unit. The eyes are controlled by head-mounted eye trackers.</font></p>
]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">miltonkeynes_tracked.flv</mydata>
	</menu>
	<menu title="Research4" intro="PhD Research">
		<mydata type="description"><![CDATA[<font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"><p align="left">Title &quot;Eye Tracking: A Perceptual Interface for Content Based Image Retrieval&quot;</p><p></p><p align="justify">Visual search experiments are devised to explore the feasibility of an eye gaze driven search mechanism. An eye tracking image retrieval interface together with precomputed similarity measures yield a significantly better performance than random selection using the same similarity information. Gaze parameters were explored to determine novel methods of inferring intention from users' gaze data.</font></p>]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">Eyes-Find.flv</mydata>
	</menu>
	<menu title="Publications" intro="PUBLICATIONS">
		<mydata type="description"><![CDATA[<p align="left"></p><p align="left">* Perez-Marcos D, Solazzi M, Steptoe W, Oyekoya O, Frisoli A, Weyrich T, Steed A, Tecchia F, Slater M and Sanchez-Vives MV. A fully immersive set-up for remote interaction and neurorehabilitation based on virtual body ownership. Frontiers in Teleneurology 3:110, 2012. doi: 10.3389/fneur.2012.00110. - <a href="http://www.frontiersin.org/teleneurology/10.3389/fneur.2012.00110/abstract" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Steptoe, W. and Normand, J.M. and Oyekoya, O. and Pece, F. and Giannopoulos, E. and Tecchia, F. and Steed, A. and Weyrich, T. and Kautz, J. and Slater, M. Acting Rehearsal in Collaborative Multimodal Mixed Reality Environments. PRESENCE: Teleoperators and Virtual Environments, 2012. - <a href="http://www.cs.ucl.ac.uk/staff/W.Steptoe/files/steptoe_actingMR_presence.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Oyekoya, O., Steptoe, W., and Steed, A. “SphereAvatar: A Situated Display to Represent a Remote Collaborator,” to appear in Proc. of CHI2012, 5-10 May 2012. - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/sphere.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Oyekoya O, Steed A., Pan X. “Exploring a Model of Gaze Animation using Human Eye Behaviour,” Joint Virtual Reality Conference (EuroVR-EGVE), 20-21 September 2011, Nottingham UK. - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/JVRC_model_paper.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Kokkinara E, Oyekoya O, Steed A. (2011). Modelling Selective Visual Attention for Autonomous Virtual Characters, Journal of Computer Animation and Virtual Worlds, CASA 2011, Chengdu, China. - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/cav425.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Oyekoya O., Newman J., Steed A., Martinez E., and Bernardet U. (2010). “Social Experiment in Heterogeneous Mixed Reality Environments”, Proc. of Real Actions in Virtual Environments 2010 Abstract, Barcelona, Mar 4. - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/OyekoyaRAVEabstract.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left">* Steptoe, W., Oyekoya, O., Steed, A. (2010). Eyelid Kinematics for Virtual Characters, CASA 2010: Proceedings of 23rd Annual Conference on Computer Animation and Social Agents, published in a special issue of Wiley’s Journal of Computer Animation and Virtual Worlds, May 31-June 2nd, Saint-Malo, France. - <a href="http://www.cs.ucl.ac.uk/staff/W.Steptoe/files/steptoeCAVW10.pdf" target = "_blank"><b>pdf</b></a></p><p></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* Oyekoya, O., Steptoe, W., and Steed, A. 2009. A saliency-based method of simulating visual attention in virtual scenes. In <i>Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology</i> (Kyoto, Japan, November 18 - 20, 2009). S. N. Spencer, Ed. VRST '09. ACM, New York, NY, 199-206. DOI= http://doi.acm.org/10.1145/1643928.1643973. - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/vrst09.pdf" target = "_blank"><b>pdf</b></a></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* D. Roberts, R. Wolff, J. Rae, A. Steed, R. Aspin, M. McIntyre, A. Pena, O.Oyekoya, and W. Steptoe (2009), Communicating Eye-gaze Across a Distance: Comparing an Eye-gaze enabled Immersive Collaborative Virtual Environment, Aligned Video Conferencing, and Being Together, in Proc. IEEE Virtual Reality, March 2009 - <a href="http://doi.ieeecomputersociety.org/10.1109/VR.2009.4811013" target = "_blank"><b>doi</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* W. Steptoe, O. Oyekoya, A. Murgia, R. Wolff, J. Rae, E. Guimaraes, D. Roberts, A. Steed, (2009) Eye-Tracking for Avatar Eye-Gaze Control during Object-Focused Multiparty Interaction in Immersive Collaborative Virtual Environments, Proc. IEEE VR, March 2009 - <a href="http://doi.ieeecomputersociety.org/10.1109/VR.2009.4811003" target = "_blank"><b>doi</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O Oyekoya and X Gao, &quot;Visualization of Volume Information from PET Data&quot;, Medical Imaging and Informatics (MIMI 2007), Beijing, China, August 2007 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/mimi2007Abstract.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* Thesis, "Eye Tracking: A Perceptual Interface for Content Based Image Retrieval", University College London, April 2007- <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/thesis/Thesis.pdf" target = "_blank"><b>pdf</b></a> (see thesis for a list of some commercial eye trackers).</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O Oyekoya and F W M Stentiford, "Perceptual Image Retrieval Using Eye Movements," International Journal of Computer Mathematics, Special Issue on Computer Vision and Pattern Recognition, Volume 84, Issue 9 September 2007 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/IJCM.pdf" target = "_blank"><b>pdf</b></a>. <font size="9"><i>Author Posting. (c) Taylor &amp; Francis, 2007. This is the author&apos;s version of the work. It is posted here by permission of Taylor &amp; Francis for personal use, not for redistribution. The definitive version was published in International Journal of Computer Mathematics, Volume 84 Issue 9, September 2007. </i><a href="http://dx.doi.org/10.1080/00207160701242268" target = "_blank"><b><i>doi:10.1080/00207160701242268</i></b></a><i>.</i></font></font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya and F W M Stentiford, "Eye Tracking: A New Interface for Visual Exploration," BT Technology Journal, vol 24, no. 3, pp 57-66, July 2006 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/BTTJ06.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O Oyekoya and F W M Stentiford, "Perceptual Image Retrieval Using Eye Movements," International Workshop on Intelligent Computing in Pattern Analysis/Synthesis, 26-27 August, Xi'an, China, 2006 - <a href="http://dx.doi.org/10.1007/11821045_30" target = "_blank"><b>doi</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya and F W M Stentiford, "Eye tracking as a new interface for image retrieval," Intelligent Spaces: the Application of Pervasive ICT, Springer-Verlag, London, pp 273-284, 2006 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/iSpaces.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O Oyekoya and F W M Stentiford, "An eye tracking interface for image search," Eye Tracking Research and Applications Symposium, San Diego, March 27-29, 2006 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/ETRAWole.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya, "Managing multimedia content: a technology roadmap," Report, SIRA Innovation Ltd, April, 2005 - [<a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/ReportFinal.pdf" target = "_blank"><b>Report</b></a>] [<a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/RoadmapFinal.pdf" target = "_blank"><b>Roadmaps</b></a>] [<a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/RoadmapPresentation.pdf" target = "_blank"><b>Presentation</b></a>]</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* Oyekoya and F W M Stentiford, "A performance comparison of eye tracking and mouse interfaces in a target identification task," European Workshop on the Integration of Knowledge, Semantics &amp; Digital Media Technology, London, 30th November - 1st December, 2005 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/OyekoyaStentifordEWIMT2005.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya &amp; F W M Stentiford, "Exploring human eye behaviour using a model of visual attention," 17th International Conference on Pattern Recognition 2004, pp. 945-948, Volume 4, 23rd - 26th August, 2004 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/ICPR2004.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya and F W M Stentiford, "Eye tracking as a new interface for image retrieval," BT Technology Journal, vol. 22, No 3, pp 161-169, July 2004 - <a href="http://web4.cs.ucl.ac.uk/staff/W.Oyekoya/BTTJpaper.pdf" target = "_blank"><b>pdf</b></a>.</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">* O K Oyekoya &amp; F W M Stentiford, "Exploring the significance of visual attention by eye tracking", London Communications Symposium, pp 149 - 152, September 8-9, 2003.</font></p><p align="left"></p>]]></mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">1.flv</mydata>
	</menu>
	<menu title="Contact" intro="CONTACT INFORMATION">
		<mydata type="description"><![CDATA[<p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">Virtual Environments and Computer Graphics Group</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">Dept. of Computer Science </font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">University College London</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">Gower Street</font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">London </font></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">WC1E 6BT</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1">Telephone +44 (0)20 7679 0356</font></p><p align="left"></p><p align="left"><font face="Arial" size="11" color="#000099" letterSpacing="0.000000" kerning="1"> Email: <a href="mailto:w.oyekoya@cs.ucl.ac.uk">w.oyekoya@cs.ucl.ac.uk</a></font></p>
]]>B</mydata>
		<mydata type="image">1.jpg</mydata>
		<mydata type="video">1.flv</mydata>
	</menu>
</links>